# Uni-Sign Stage 3 多模态改进分步修改逻辑

## 任务目标
对Uni-Sign模型进行Stage 3多模态改进，引入视频动作文本描述作为辅助模态，提升模型表现。

## 方案核心
- 新增文本模态：引入description/文件夹下的动作描述文本，作为辅助输入。
- 文本编码器：采用mT5-base对描述文本编码。
- 时间对齐：采用智能插值策略，实现描述与视频帧的对齐。
- 融合机制：采用Gating机制融合视觉/姿态特征与文本特征。
- 缺失模态处理：
  - 缺失描述时，使用可学习掩码（mask embedding）作为占位。
  - 训练阶段引入Text Dropout，增强鲁棒性。
  - 推理阶段显式使用缺失指示符。

## 分步修改逻辑

### 步骤1：数据加载与预处理（datasets.py）
- 加载每个样本的动作描述文本（支持部分/全部缺失）。
- 生成每一帧对应的描述文本索引（__frame_indices__），便于后续对齐与插值。
- 返回结构需包含：视觉/姿态特征、目标文本、描述文本（list of str 或 None）、帧索引、缺失指示符。
- 支持配置/参数控制是否启用描述文本。

### 步骤2：文本编码器集成（models.py 或 text_fusion_modules.py）
- 新建TextEncoder模块，封装mT5-base加载与编码逻辑。
- 冻结mT5参数，仅做特征提取。
- 缺失描述时，输出可学习掩码embedding。

### 步骤3：时序对齐与智能插值（temporal_alignment.py）
- 实现智能插值策略：
  - 有描述帧直接用描述。
  - 最近帧有描述则用最近帧。
  - 两侧都无则线性插值。
- 输出每帧的文本特征及缺失指示符。

### 步骤4：融合机制实现（text_fusion_modules.py 或 models.py）
- 实现Gating Fusion模块：
  - 输入：视觉/姿态特征、文本特征、缺失指示符。
  - 输出：融合后的多模态特征。
- 支持可配置的融合方式（如后续切换Cross-Attention）。

### 步骤5：主模型集成与训练流程调整（models.py、fine_tuning.py）
- 在主模型中集成文本编码与融合模块。
- forward流程支持多模态输入，兼容缺失模态。
- 训练阶段引入Text Dropout策略。
- 推理阶段显式使用缺失指示符。

### 步骤6：参数与命令行支持（utils.py、fine_tuning.py）
- 增加/调整命令行参数，支持是否启用描述文本、融合方式、Dropout概率等。
- 保证兼容无描述/部分描述场景。

### 步骤7：单元测试与兼容性检查
- 针对每个模块编写单元测试，确保各环节功能正确。
- 检查无描述、部分描述、全描述等多种场景下的兼容性。

---

如需详细代码实现方案，可按上述步骤逐步展开。