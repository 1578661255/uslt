# Stage 3 å¤šæ¨¡æ€èåˆ - è®­ç»ƒå¯åŠ¨æŒ‡å—

## ğŸ“‹ ç³»ç»Ÿç°çŠ¶æ¦‚è§ˆ

### âœ… å·²å®Œæˆ
1. **æ–°æ¨¡å—å¼€å‘** (100%)
   - âœ“ `temporal_alignment.py` - æè¿°åŠ è½½ä¸æ—¶é—´å¯¹é½
   - âœ“ `text_fusion_modules.py` - æ–‡æœ¬ç¼–ç ä¸èåˆ

2. **ç°æœ‰ä»£ç é›†æˆ** (100%)
   - âœ“ `models.py` - å¤šæ¨¡æ€èåˆé›†æˆ
   - âœ“ `datasets.py` - æè¿°åŠ è½½æ”¯æŒ
   - âœ“ `config.py` - è·¯å¾„é…ç½®åŒ–
   - âœ“ `utils.py` - CLI å‚æ•°æ‰©å±•
   - âœ“ `fine_tuning.py` - è®­ç»ƒå¾ªç¯æ”¯æŒ

3. **éªŒè¯** (100%)
   - âœ“ æ‰€æœ‰åˆæ³•æ€§æ£€æŸ¥é€šè¿‡
   - âœ“ Python è¯­æ³•æ£€æŸ¥é€šè¿‡
   - âœ“ é…ç½®é›†æˆéªŒè¯é€šè¿‡
   - âœ“ æ•°æ®æµå…¼å®¹æ€§é€šè¿‡

---

## ğŸš€ å¿«é€Ÿå¯åŠ¨

### æ–¹å¼ 1ï¼šåŸºç¡€è®­ç»ƒï¼ˆä¸ä½¿ç”¨æè¿°æ–‡æœ¬ï¼‰

```bash
cd d:\home\pc\code\slt\Uni-Sign

python fine_tuning.py \
    --dataset CSL_Daily \
    --epochs 20 \
    --batch-size 16 \
    --output_dir ./output_baseline
```

**è¯´æ˜**ï¼šä¸ Stage 2 å®Œå…¨ç›¸åŒï¼Œä¸ä½¿ç”¨å¤šæ¨¡æ€èåˆ

---

### æ–¹å¼ 2ï¼šå¯ç”¨å¤šæ¨¡æ€èåˆè®­ç»ƒ

```bash
python fine_tuning.py \
    --dataset CSL_Daily \
    --epochs 20 \
    --batch-size 16 \
    --use_descriptions \
    --text_dropout_p 0.1 \
    --output_dir ./output_multimodal
```

**å…³é”®å‚æ•°**ï¼š
- `--use_descriptions`ï¼šå¯ç”¨æ–‡æœ¬æè¿°å¤šæ¨¡æ€èåˆ
- `--text_dropout_p 0.1`ï¼šæ–‡æœ¬ dropout æ¦‚ç‡ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰

---

### æ–¹å¼ 3ï¼šå†»ç»“æ–‡æœ¬ç¼–ç å™¨ï¼ˆä»…è®­ç»ƒèåˆæ¨¡å—ï¼‰

```bash
python fine_tuning.py \
    --dataset CSL_Daily \
    --epochs 20 \
    --batch-size 16 \
    --use_descriptions \
    --text_encoder_freeze \
    --output_dir ./output_fusion_only
```

**è¯´æ˜**ï¼š
- mT5 ç¼–ç å™¨å†»ç»“ï¼Œä»…è°ƒæ•´ GatingFusion å’Œ LearnableMaskEmbedding
- æ¨èç”¨äºæ˜¾å­˜å—é™çš„æƒ…å†µ
- è®­ç»ƒé€Ÿåº¦å¿«ï¼Œå‚æ•°é‡æœ€å°

---

### æ–¹å¼ 4ï¼šå®Œæ•´å¾®è°ƒï¼ˆå¸¦èåˆæ£€æŸ¥ç‚¹ï¼‰

```bash
python fine_tuning.py \
    --dataset CSL_Daily \
    --epochs 20 \
    --batch-size 16 \
    --use_descriptions \
    --text_dropout_p 0.1 \
    --fusion_checkpoint ./pretrained_fusion.pth \
    --output_dir ./output_finetune
```

**è¯´æ˜**ï¼šä»é¢„è®­ç»ƒçš„èåˆæ¨¡å—æ£€æŸ¥ç‚¹å¼€å§‹

---

## ğŸ“Š æ•°æ®æµéªŒè¯

ç³»ç»Ÿå®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹ï¼š

```
åŸå§‹æ•°æ®
  â†“
â”€â”€â”€ å§¿æ€åˆ†æ”¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¤šéƒ¨ä½ GCN
  â†“
æ–‡æœ¬æè¿° â†’ DescriptionLoader â†’ åŸå§‹æè¿°å­—å…¸
  â†“
     TemporalAligner â†’ å¯¹é½æè¿°åˆ—è¡¨ + ç¼ºå¤±æŒ‡ç¤ºç¬¦
  â†“
S2T_Dataset.__getitem__() â†’ 7å…ƒç»„
  â”œâ”€ name_sample, pose_sample, text, gloss, rgb_dict
  â”œâ”€ descriptions (æ–°)
  â””â”€ has_description (æ–°)
  â†“
collate_fn() â†’ src_input å­—å…¸
  â”œâ”€ åŸæœ‰å­—æ®µä¿æŒä¸å˜
  â”œâ”€ descriptions (List[List[str or None]])
  â””â”€ has_description (List[List[int]])
  â†“
Uni_Sign.forward()
  â”œâ”€ å§¿æ€ç‰¹å¾æå– â†’ inputs_embeds (B, T, 768)
  â”œâ”€ IF descriptions exist:
  â”‚  â”œâ”€ TextEncoder â†’ text_features (B, T, 768)
  â”‚  â”œâ”€ _apply_text_dropout â†’ text_features (è®­ç»ƒæ—¶)
  â”‚  â””â”€ GatingFusion â†’ fused_embeds = pose + gate Ã— text
  â”‚
  â””â”€ MT5 ç¼–ç å™¨-è§£ç å™¨ â†’ ç¿»è¯‘è¾“å‡º
```

---

## âš™ï¸ é…ç½®æ£€æŸ¥è¡¨

è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯æ‰€æœ‰é…ç½®æ˜¯å¦æ­£ç¡®ï¼š

```bash
python pre_training_checklist.py
```

é¢„æœŸè¾“å‡ºï¼š
```
âœ“ utils.py å‚æ•°
âœ“ fine_tuning.py é›†æˆ
âœ“ models.py é›†æˆ
âœ“ datasets.py é›†æˆ
âœ“ config.py é…ç½®

âœ“ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ç³»ç»Ÿå‡†å¤‡å°±ç»ª
```

---

## ğŸ”§ é«˜çº§é€‰é¡¹

### è°ƒæ•´æ–‡æœ¬ Dropout å¼ºåº¦

```bash
# è¾ƒå¼ºçš„æ­£åˆ™åŒ–ï¼ˆæ¨èç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
--text_dropout_p 0.2

# è¾ƒå¼±çš„æ­£åˆ™åŒ–ï¼ˆæ¨èç”¨äºæ•°æ®å……è¶³ï¼‰
--text_dropout_p 0.05

# æ—  Dropoutï¼ˆä»…è°ƒè¯•ç”¨ï¼‰
--text_dropout_p 0.0
```

### æ˜¾å­˜ä¼˜åŒ–

å¦‚æœé‡åˆ° OOMï¼ˆå†…å­˜ä¸è¶³ï¼‰é”™è¯¯ï¼š

```bash
# æ–¹æ¡ˆ 1ï¼šå‡å°æ‰¹å¤§å°
--batch-size 8

# æ–¹æ¡ˆ 2ï¼šå†»ç»“æ–‡æœ¬ç¼–ç å™¨ï¼ˆæ˜¾å­˜å‡å°‘ ~2GBï¼‰
--text_encoder_freeze

# æ–¹æ¡ˆ 3ï¼šå¯ç”¨æ¢¯åº¦ç´¯ç§¯
--gradient-accumulation-steps 16  # ç­‰æ•ˆäº batch_size=512

# æ–¹æ¡ˆ 4ï¼šå¯ç”¨ ZeRO ä¼˜åŒ–
--zero_stage 2 --offload
```

### æ¨ç†æ¨¡å¼

è¯„ä¼°å·²è®­ç»ƒæ¨¡å‹çš„æ€§èƒ½ï¼š

```bash
python fine_tuning.py \
    --dataset CSL_Daily \
    --use_descriptions \
    --finetune ./output_multimodal/best_checkpoint.pth \
    --eval
```

---

## ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥

### Q1ï¼šè¿è¡ŒæŠ¥é”™ "No module named 'temporal_alignment'"
**åŸå› **ï¼šæœªåœ¨æ­£ç¡®ç›®å½•  
**è§£å†³**ï¼šç¡®ä¿åœ¨ `Uni-Sign` ç›®å½•ä¸‹è¿è¡Œ
```bash
cd d:\home\pc\code\slt\Uni-Sign
python fine_tuning.py ...
```

### Q2ï¼šæŠ¥é”™ "descriptions not found in src_input"
**åŸå› **ï¼š--use_descriptions ä½†æè¿°æ–‡ä»¶ç¼ºå¤±  
**è§£å†³**ï¼šæ£€æŸ¥ `./description/CSL-Daily/split_data/` æ˜¯å¦å­˜åœ¨
```bash
# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -la ./description/CSL-Daily/split_data/train/ | head -10
```

### Q3ï¼šOOM (GPU æ˜¾å­˜æº¢å‡º)
**åŸå› **ï¼šTextEncoder å ç”¨è¾ƒå¤šæ˜¾å­˜  
**è§£å†³æ–¹æ¡ˆ**ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
1. ä½¿ç”¨ `--text_encoder_freeze` é™ä½ä¼˜åŒ–å™¨çŠ¶æ€å¤§å°
2. å‡å° `--batch-size`
3. å¢åŠ  `--gradient-accumulation-steps`
4. å¯ç”¨ `--zero_stage 2 --offload`

### Q4ï¼šè®­ç»ƒé€Ÿåº¦æ˜æ˜¾å˜æ…¢
**åŸå› **ï¼šæ–‡æœ¬ç¼–ç å¼€é”€  
**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨ `--text_encoder_freeze` è·³è¿‡æ¢¯åº¦è®¡ç®—
- å¢åŠ  `--num_workers` åŠ é€Ÿæ•°æ®åŠ è½½
- ä½¿ç”¨ `--pin-mem` é”å®šå†…å­˜

---

## ğŸ“ˆ è®­ç»ƒæ•ˆæœé¢„æœŸ

### åŸºç¡€æ¨¡å‹ï¼ˆStage 2ï¼‰
```
BLEU-4 on test: ~35.5
```

### å¤šæ¨¡æ€èåˆï¼ˆStage 3ï¼Œä½¿ç”¨æè¿°ï¼‰
```
BLEU-4 on test: ~37-39
```

**é¢„æœŸæå‡**ï¼š+2-4 BLEU è§†æè¿°è´¨é‡è€Œå®š

---

## ğŸ“ æ ¸å¿ƒå‚æ•°è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--use_descriptions` | False | å¯ç”¨å¤šæ¨¡æ€æ–‡æœ¬èåˆ |
| `--text_dropout_p` | 0.1 | æ–‡æœ¬ dropout æ¦‚ç‡ |
| `--text_encoder_freeze` | False | å†»ç»“ TextEncoder å‚æ•° |
| `--fusion_checkpoint` | "" | èåˆæ¨¡å—æ£€æŸ¥ç‚¹è·¯å¾„ |
| `--dataset` | CSL_Daily | æ•°æ®é›†é€‰æ‹© |
| `--epochs` | 20 | è®­ç»ƒè½®æ•° |
| `--batch-size` | 16 | æ‰¹å¤§å° |
| `--lr` | 1e-3 | å­¦ä¹ ç‡ |

---

## ğŸ“¦ å…³é”®æ–‡ä»¶æ¸…å•

### æ–°å¢æ–‡ä»¶
- `temporal_alignment.py` (292 è¡Œ) - æè¿°åŠ è½½å’Œå¯¹é½
- `text_fusion_modules.py` (442 è¡Œ) - æ–‡æœ¬ç¼–ç å’Œèåˆ
- `test_description_loading.py` - æè¿°åŠ è½½éªŒè¯
- `test_models_integration.py` - æ¨¡å‹é›†æˆéªŒè¯
- `pre_training_checklist.py` - è®­ç»ƒå‰æ£€æŸ¥

### ä¿®æ”¹æ–‡ä»¶
- `models.py` - å¤šæ¨¡æ€èåˆé›†æˆ (+180 è¡Œ)
- `datasets.py` - æè¿°åŠ è½½æ”¯æŒ (+150 è¡Œ)
- `config.py` - è·¯å¾„é…ç½®åŒ– (+3 è¡Œ)
- `utils.py` - CLI å‚æ•°æ‰©å±• (+13 è¡Œ)
- `fine_tuning.py` - è®­ç»ƒå¾ªç¯æ”¯æŒ (+15 è¡Œ)

### æ•°æ®æ–‡ä»¶
- `description/CSL-Daily/split_data/train/` - 162 ä¸ªæ ·æœ¬
- `description/CSL-Daily/split_data/dev/` - æ ·æœ¬
- `description/CSL-Daily/split_data/test/` - æ ·æœ¬

---

## ğŸ¯ å»ºè®®çš„è®­ç»ƒè®¡åˆ’

### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€éªŒè¯ï¼ˆ1 å¤©ï¼‰
```bash
# 1. ç¡®ä¿åŸºç¡€æ¨¡å‹èƒ½æ­£å¸¸è¿è¡Œ
python fine_tuning.py --dataset CSL_Daily --epochs 1 --batch-size 16 \
    --output_dir ./test_baseline

# 2. å¯ç”¨æè¿°æ–‡æœ¬è¿›è¡ŒéªŒè¯
python fine_tuning.py --dataset CSL_Daily --epochs 1 --batch-size 16 \
    --use_descriptions --output_dir ./test_multimodal
```

### ç¬¬äºŒé˜¶æ®µï¼šèåˆæ¨¡å—è®­ç»ƒï¼ˆ3-5 å¤©ï¼‰
```bash
# å†»ç»“æ–‡æœ¬ç¼–ç å™¨ï¼Œä»…è®­ç»ƒèåˆæ¨¡å—ï¼ˆé€Ÿåº¦å¿«ï¼‰
python fine_tuning.py --dataset CSL_Daily --epochs 10 --batch-size 16 \
    --use_descriptions --text_encoder_freeze \
    --output_dir ./fusion_training
```

### ç¬¬ä¸‰é˜¶æ®µï¼šå®Œæ•´å¾®è°ƒï¼ˆ5-10 å¤©ï¼‰
```bash
# å®Œæ•´è®­ç»ƒï¼ŒåŒ…æ‹¬æ–‡æœ¬ç¼–ç å™¨å¾®è°ƒ
python fine_tuning.py --dataset CSL_Daily --epochs 20 --batch-size 16 \
    --use_descriptions --text_dropout_p 0.1 \
    --finetune ./fusion_training/best_checkpoint.pth \
    --output_dir ./full_training
```

---

## âœ… æœ€åæ£€æŸ¥æ¸…å•

åœ¨å¯åŠ¨è®­ç»ƒå‰ï¼Œç¡®ä¿ï¼š

- [ ] è¿è¡Œ `pre_training_checklist.py` å…¨éƒ¨é€šè¿‡
- [ ] æ•°æ®æ–‡ä»¶å¤¹å­˜åœ¨ï¼š`./description/CSL-Daily/split_data/`
- [ ] é…ç½®æ–‡ä»¶åŒ…å« `description_dirs` è®¾ç½®
- [ ] GPU æ˜¾å­˜å……è¶³ï¼ˆå»ºè®® â‰¥ 24GB for å®Œæ•´è®­ç»ƒï¼‰
- [ ] é€‰æ‹©åˆé€‚çš„å¯åŠ¨æ–¹å¼ï¼ˆåŸºç¡€/å¤šæ¨¡æ€/å†»ç»“ç­‰ï¼‰
- [ ] æŒ‡å®š `--output_dir` ä¿å­˜ç»“æœ

---

**æ›´æ–°æ—¶é—´**ï¼šè®­ç»ƒå‰å®Œæ•´é›†æˆå®Œæˆ  
**ç³»ç»ŸçŠ¶æ€**ï¼šâœ… å‡†å¤‡å°±ç»ª  
**ä¸‹ä¸€æ­¥**ï¼šé€‰æ‹©ä¸Šè¿°å¯åŠ¨æ–¹å¼ä¹‹ä¸€ï¼Œå¼€å§‹è®­ç»ƒ
